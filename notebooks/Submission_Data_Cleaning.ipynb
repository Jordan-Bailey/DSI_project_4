{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Scoring and Kaggle Submisisons\n",
    "\n",
    "In this notebook we will score all the models we made and select the best one for future use. This will require some brief data cleaning for the test data which we include below, it __mostly__ follows the same pattern as the cleaning of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "weather = pd.read_csv('../data/weather_cleaned.csv')\n",
    "spray = pd.read_csv('../data/spray_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = test.columns.map(lambda x: x.lower())\n",
    "weather.columns = weather.columns.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.species = test.species.map({'CULEX PIPIENS/RESTUANS': 'CULEX PIPIENS/RESTUANS',\n",
    "                   'CULEX RESTUANS': 'CULEX RESTUANS',\n",
    "                   'CULEX PIPIENS': 'CULEX PIPIENS',\n",
    "                   'CULEX TERRITANS': 'CULEX OTHER', \n",
    "                   'CULEX SALINARIUS': 'CULEX OTHER',\n",
    "                   'CULEX TARSALIS': 'CULEX OTHER',\n",
    "                   'CULEX ERRATICUS': 'CULEX OTHER'})\n",
    "\n",
    "test.species = test.species.fillna('CULEX PIPIENS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'address', 'species', 'block', 'street', 'trap',\n",
       "       'addressnumberandstreet', 'latitude', 'longitude', 'addressaccuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['station'] = np.where(test['latitude'] >= 41.892, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_weather = pd.merge(test, weather, on=['date', 'station'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_weather_spray_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nummosquitos', 'spray_nearby', 'wnvpresent'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns).difference(test_weather.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only final feature to engineer for test data is the `spray_nearby` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, radians, asin, sqrt\n",
    "def global_distance(lon1, lat1, lon2, lat2):\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3956\n",
    "    \n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traps = {}\n",
    "for index, row in test_weather.iterrows():\n",
    "    traps[row['trap']] = (row['longitude'], row['latitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trap_distances = {}\n",
    "\n",
    "for trap in traps:\n",
    "    lon, lat = traps[trap]\n",
    "    \n",
    "    for index, spray_row in spray.iterrows():\n",
    "        tmp_dist = global_distance(lon, lat, spray_row['Longitude'], spray_row['Latitude'])\n",
    "        if trap in trap_distances:\n",
    "            trap_distances[trap] = min(tmp_dist, trap_distances[trap])\n",
    "        else:\n",
    "            trap_distances[trap] = tmp_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the only features we're actually using for our models, so we'll store our testing data so that it can be easily accessed by these names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['latitude', 'longitude', 'addressaccuracy', 'spray_nearby', 'station',\n",
    "       'tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "       'avgspeed', 'ts', 'sq', 'fg+', 'gr', 'br', 'tsra', 'dz', 'bcfg', 'hz',\n",
    "       'fu', 'sn', 'fg', 'vcts', 'ra', 'mifg', 'vcfg', 'species_CULEX OTHER',\n",
    "       'species_CULEX PIPIENS', 'species_CULEX PIPIENS/RESTUANS',\n",
    "       'species_CULEX RESTUANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weather['spray_nearby'] = (test_weather['trap'].map(trap_distances) < .125).map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weather_dummies = pd.get_dummies(test_weather, columns=['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just doing a brief check that the shape is what we expect, we should have 38 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weather_dummies = test_weather_dummies[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 38)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weather_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have one object type, `preciptotal` and we should convert the 'T' for trace amounts to a very small floating point like we did in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weather_dummies.select_dtypes(include='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weather_dummies.to_csv('../data/test_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scoring\n",
    "We want to look to our training data to collect all of our scores here and our testing data so we can create and score our predictions for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(train, columns=['species'])[cols]\n",
    "y = pd.read_csv('../data/train_weather_spray_merged.csv')['wnvpresent']\n",
    "\n",
    "with open('../models/scaler.pkl', 'rb') as ss_prefit:\n",
    "    ss = pickle.load(ss_prefit)\n",
    "\n",
    "with open('../models/pca.pkl', 'rb') as pca_prefit:\n",
    "    pca = pickle.load(pca_prefit)\n",
    "    \n",
    "with open('../models/pca_restricted.pkl', 'rb') as pca_prefit_rest:\n",
    "    pca_rest = pickle.load(pca_prefit_rest)\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=41)\n",
    "\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "test_weather_dummies = ss.transform(test_weather_dummies)\n",
    "\n",
    "#for the models with PCA and all features. \n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "test_weather_dummies_pca = pca.transform(test_weather_dummies)\n",
    "    \n",
    "#for the models with PCA and limited features. \n",
    "limited_cols = ['latitude', 'longitude', 'tmax', 'species_CULEX PIPIENS']\n",
    "X_cols = X.columns.tolist()\n",
    "limited_cols = [X_cols.index(col) for col in limited_cols]\n",
    "\n",
    "X_train_limited = X_train[:,limited_cols]\n",
    "X_test_limited = X_test[:,limited_cols]\n",
    "test_weather_dummies_limited = test_weather_dummies[:,limited_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_submission(name, model, test_data):\n",
    "    preds = model.predict_proba(test_data)[:,1]\n",
    "    preds = pd.Series(data=preds, index=range(1,preds.shape[0]+1))\n",
    "    preds.to_csv(f'../kaggle_submissions/{name}.csv', index=True, index_label='Id', header=['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll use a dictionary to keep track of our scores\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Adaboost with PCA\n",
    "First we assess our models with a full set of features that was reduced with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/ada.pkl', 'rb') as file:\n",
    "    ada = pickle.load(file)\n",
    "    \n",
    "model_submission('ada', ada, test_weather_dummies_pca)\n",
    "scores['ada'] = ada.score(X_train_pca, y_train), ada.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/log_reg_pca.pkl', 'rb') as file:\n",
    "    log_reg_pca = pickle.load(file)\n",
    "    \n",
    "model_submission('log_reg_pca', log_reg_pca, test_weather_dummies_pca)\n",
    "scores['log_reg_pca'] = log_reg_pca.score(X_train_pca, y_train), log_reg_pca.score(X_test_pca, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, Decision Tree, Random Forest, Bagged Decision Tree and KNN\n",
    "Most of the models we tried, we did without using PCA first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/dt.pkl', 'rb') as file:\n",
    "    dt = pickle.load(file)\n",
    "    \n",
    "model_submission('dt', dt, test_weather_dummies)\n",
    "scores['dt'] = dt.score(X_train, y_train), dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/rf.pkl', 'rb') as file:\n",
    "    rf = pickle.load(file)\n",
    "    \n",
    "model_submission('rf', rf, test_weather_dummies)\n",
    "scores['rf'] = rf.score(X_train, y_train), rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/bag.pkl', 'rb') as file:\n",
    "    bag = pickle.load(file)\n",
    "    \n",
    "model_submission('bag', bag, test_weather_dummies)\n",
    "scores['bag'] = bag.score(X_train, y_train), bag.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/knn.pkl', 'rb') as file:\n",
    "    knn = pickle.load(file)\n",
    "    \n",
    "model_submission('knn', knn, test_weather_dummies)\n",
    "scores['knn'] = knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Random Forest with restricted features\n",
    "We tried a few models with a restricted feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/dt_lf.pkl', 'rb') as file:\n",
    "    dt_lf = pickle.load(file)\n",
    "    \n",
    "model_submission('dt_lf', dt_lf, test_weather_dummies_limited)\n",
    "scores['dt_lf'] = dt_lf.score(X_train_pca_rest, y_train), dt_lf.score(X_test_pca_rest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/rf_lf.pkl', 'rb') as file:\n",
    "    rf_lf = pickle.load(file)\n",
    "    \n",
    "model_submission('rf_lf', rf_lf, test_weather_dummies_limited)\n",
    "scores['rf_lf'] = rf_lf.score(X_train_pca_rest, y_train), rf_lf.score(X_test_pca_rest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01291549665014884, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_pca.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
